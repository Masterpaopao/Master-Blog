## 工作笔记

>入职公司：XXXX
>
>入职岗位：Python数据分析工程师、量化工程师

---

### Week-1

#### 2022-03-02

岗位要求：

- Python基础扎实
  - 面试通过
- Pandas灵活玩转，已备网盘视频进行学习
  - 网盘链接：https://pan.baidu.com/share/init?surl=9wD-Xe6Bm8OF-kt_FD7Xyg
  - 提取码：kw0g
- 学习原生echarts
  - 官方文档：https://echarts.apache.org/handbook/zh/get-started/
- 购买《Python股票量化交易从入门到实践》
  - 已于2022-03-06收到货

---

#### 2022-03-03

Pandas值得记录的知识：

```python
①set_option()学习
    参数"expand_frame_repr"：设定dataframe数据显示的规则，为False不忽略中间的列，完整展示
    pd.options.display.precision = 1：规定数据的浮点数精度为1
②read_csv()学习
	names与header的结合用法：我们可以通过names重新定义表头，然后header=0进行覆盖
    encoding参数：如果是含有中文字符的csv文件，需要将指定gbk编码
    sep参数：代表数据的分隔符，默认值是英文逗号，其他常见的有'\t'
    skiprows参数：跳过前n行的数据，n+1行作为表头，也就是说表头在计数范围
    nrows参数：除去表头，只读取前n行的数据，默认是全部读取，注意，表头不在计数范围内
    usecols参数：读取指定的这几列数据，其他列数据不读
    parse_dates参数，将指定列的数据从字符串识别为日期格式
    error_bad_lines参数：设定为False时，遇到有问题的行数据直接跳过
    na_values参数：碰到NULL数据设定为空值
    index_col参数：默认是从0开始做索引，可以指定交易日期为索引列
③查看dataframe数据
    df.shape：输出多少行多少列，注意是不包含表头和指定的索引列
    df.shape[0]、df.shape[1]：输出行的数量或列的数量
    df.columns：输出每一列的名字，表头的名字，可for循环
    df.index：输出每一行的名字，索引的名字，可for循环
    df.head()、df.tail()：看前n行数据和后n行数据，默认是5，忽略表头
    df.sample(n=3)：随机抽取n行数据
    df.describe()：直观感受数据
④读取dataframe指定的数据
    列表访问：如果要访问两个列的数据，需要传递列表参数
    df.loc[]、df.at[]：通过index和columns来访问数据，也可以用切片的方式指定范围，前者是多元素，后者为单
    df.iloc[]、df.iat[]：通过行号和列号来来访问数据，前者是多元素，后者为单
```



---

#### 2022-03-04

微信推送图片项目实战：

- 将实习生写的代码进行了一次大重构
  - 因每个电脑需要的数据不同，将所有常量和公共函数放进data.py
  - 每一个函数命名讲究化，并带有函数功能注释
  - 因为Mac和Windows操作逻辑的不同，发送消息的逻辑作出修改
- 后续优化
  - 取消多余的逻辑动作，取消重复选择群组发送消息的逻辑
  - 因为发送到三个群的消息是相同的，优化到消息只需要在redis存储一份，图片生成一份，发送到三个群
  - 优化图片生成的位置，以image文件夹为主目录，再根据日期继续生成日期文件夹，将图片存储进去

---

### Week-2

#### 2022-03-07

继续学习Pandas：

```python
①dataframe数据的列操作
    根据数据的类型，可以进行加减乘除操作
    用赋值的方式可以新增一个列
    mean()：求一整列的平均值，返回一个值，会自动排除空值；如果是多列，传递列表参数
    mean()中axis参数：对两列数据中的每一行求平均值
    max()、min()、std()、median()、quantile(0.5)：最大值、最小值、标准差、中位数、25%分位数
    count()：非空的数据量
    del：删除某一列
    drop(["详细交易日期"], axis=1)：删除某一列的另一种方式，但是不影响df本身，建议带上inplace=True
    cumsum()、cumprod(): 累加值、累乘值
    value_counts()：元素相同值的个数，只能print()直接打印
②比较函数类型
    shift(-1)：删除首行数值，剩余数据向上挪动，会导致最后一个数值为NaN空值
    shift(1)：删除尾行数值，剩余数据向下挪动，会导致第一个数值为NaN空值
    diff(-1)：将本行数据对比下行数据得到差值，会导致最后一个数值为NaN空值
    diff(1)：将本行数据对比上行数据得到差值，会导致第一个数值为NaN空值
    pct_change(1): 将本行数据对比上行数据得到百分比差值，会导致第一个数值为NaN空值
    rank()：排名函数，参数ascending代表排序方式，参数pct为True时按百分比排名
```

继续微信项目实战：

- 尝试使用excel2img模块优化

  - 思路：可以直接将csv文件或者excel文件直接转图片

  - 需要先安装Excel才能正常使用本模块

    - ```python
      import excel2img
      ```

    - ```python
      excel2img.export_img("csv\sh600000.csv","result.png", "sh600000")
      ```

  - 使用效果很好，不管数据有多少行，只需要等一会就能制作成一张图片

  - 在同样的四千多行数据之下，解决了dataframe_image最多只能输出100行数据为一张图片一共需要四十六张图片的痛点，时间效率也大大提升
  
- 设置redis消息队列

  - 要保证随时能监听到新的数据，故需要redis队列
  - 方法就是lpush推送数据进去，然后while True与brpop结合，死循环监听新数据

- 明天的任务

  - 继续往后学一节pandas
  - 项目部署到windows虚拟机上
  - 思考列数据含有E的情况下，如何用科学计数法转化，比如保留两位小数转化为字符串
  - 写一个生成excel文件的函数，这是客户需要，数据需要经过处理

---

#### 2022-03-08

- 股票与股票价格的学习

股票：`股票是股份公司发行的所有权的凭证，是股份公司为筹集资金而发行给各个股东作为持股凭证并借以取得股息和红利的一种有价证券。`每股股票都代表股东对企业拥有的一个基本单位的所有权，本质上是股东拥有公司股份的凭证。

股票溢价：奔驰GLE的价值是50万元，现售价为55万元，溢价倍数=售价/价值=1.1倍，这里的`溢价倍数就是市盈率指标，它是评估股价水平是否合理的常用指标之一`。`每股收益是每一个股份所获得的收益情况`，假如这家公司税后利润20万元，一共20万元，那每股收益就是20万/20万=1。

**股价 = 每股收益 x 市盈率，P = EPS x PE**

股票收益：一般由两部分组成，分红和溢价收益。一句话公式解释为投资收益=卖出价-买入价+持有期间分红。但是在现实中，分红收益显得微不足道，股价波动带来的收益才是财富的主要来源。一般有两种形式：`投资思维：低价买入高价卖出和投机思维：等待有人以更高的价格接盘。`但是要注意第二种方式最终获利的肯定是庄家，用对倒拉升的方式哄抬股价，让散户最后接盘，所以一般更倾向于第一种方式。

所以在投资股票的时候需要考虑两个方面，一个是每股收益，一个是市盈率，来评估公司未来的前景和经营状况。心理因素也更重要，在牛市末期的时候散户盲目买入一脚踏空，在熊市末期的时候股价已经趴在地板上了散户还是选择让出廉价的筹码。巴菲特说过：“在别人恐惧的时候贪婪，在别人贪婪的时候我恐惧。”

- 继续学习Pandas

```python
①数据筛选
    用判等==去逐行判断是否符合要求，返回True或False
    想要过滤出符合条件的行数据，将条件放进df索引列表里面即可
    如果要过滤出符合多个条件的数据需要使用isin方法，参数传列表
    也可以用> >= < <= 过滤数据，也可以用&和|进行与或操作，需要双方括起来
②空缺值处理，inplace=True代表覆盖原df
    df.dropna(how="any")，将带有空值的行删掉
    df.dropna(subset=["月头","开盘价"], how="all")，all表示只有月头和开盘价都为空值的时候才删掉
    df.fillna(value=0)，将空值赋值为固定的值
    df.fillna(method="ffill")，向上寻找最近的一个非空值，以该值来填充
    df.fillna(method="bfill")，向下寻找最近的一个非空值，以该值来填充
    df.notnull()、df.isnull()，对所有数据判断是否为空值，返回True或False，放df列表索引里过滤
```

- 继续优化微信项目实战
  - 因组长要求，目前只使用dataframe_image输出图片，暂不考虑excel2img，故补一句微信消息完善提醒
  - 完成昨天的需求，如果大额数字含有E，该怎么处理数据，保留两位小数点转化为字符串
    - pandas设置精度`pandas.options.display.precision = 2`
    - `astype(str)`方法可以将列的数据类型转化为字符串
  - 增加一个输出Excel文件的功能，这是客户的需要
    - 安装openpyxl第三方库
    - pandas.ExcelWriter()生成excel对象，有workbook属性也有sheet属性
    - 踩坑：给Excel某些列设定列宽的时候，传的是数据表头参数一直疯狂报错，到后面才发现Excel设置列宽的传参对象是ABCD……列！
    - 使用了df.T的转置方法，进一步推算出了指定的表头对应的是哪个大写字母列

---

#### 2022-03-09

- Git知识复习
  - 之前学习记录的博客链接
  - https://github.com/Masterpaopao/Git-And-Github/blob/master/Git%E9%AB%98%E9%98%B6/Git%E9%AB%98%E9%98%B6%E5%AD%A6%E4%B9%A0.md

```
先在新设备网页端上面上传SSH地址打通设备权限
将项目推送到本地：git clone
突破Git上传文件大小限制：git config http.postBuffer 524288000
查看当前的分支情况，后面加名字就是创建分支：git branch
切换到某分支：git checkout
创建一条新分支并切换过去：git checkout -b xxxx
向暂存区加入改动并提交：git add + git commit -m "描述"
查看当前分支状态是否干净：git status
将某分支合并到当前分支：git merge
删除当前分支，无视状态强行删除当前分支：git branch -d/-D
将远程分支的内容同步到本地：git pull
将本地分支的内容推送到远程：git push origin
```

- 继续学习Pandas

```python
①dataframe数据整理
    df.sort_values()，根据列值排序，by是排序项，ascending是0和1选择逆序还是顺序，传列表参数
    df.append()，合并操作，ignore_index参数为True时忽略各自原来的索引
    df.drop_duplicates()，去重操作，subset参数指定需要比对的列，keep是去除重复行的时候保留first,last,False，还有inplace
    df.reset_index()，在上面的数据中重新排序索引，drop为True时删除掉各自原来的索引，还有inplace
    df.rename(columns={"开盘价":"割韭菜价"})，修改表头，以字典的形式修改表头名字
    df.empty、df.T：前者是判断df数据是否为空，返回布尔值；后者是df数据转置
②字符串操作
    df[].str[:2]，切片操作
    df[].str.upper()、df[].str.lower()，全大写或全小写操作
    df[].str.len()、df[].str.strip()，长度操作，删两端空白操作
    df[].str.contains("sh")，是否包含子串
    df[].str.replace("sh", "qq")，替换子串
```

---

#### 2022-03-10

- 学完整个pandas基础

```python
①时间处理
    pd.to_datetime()，给定一个时间字符串，智能识别出日期，但不能识别中文
    df[].dt.year/month/week/day/hour/minute/second，返回年月周日时分秒，注意原日期数据需要先parse_dates序列化
    df[].dt.dayofyear/dayofweek/weekday/day_name()，前者是返回一年的第几天，中间都是返回一周的第几天，最后是星期几
    df[].dt.days_in_month，查询这一天所在的月份有多少天
    df[].dt.is_month_start/is_month_end，查询这一天是否是本月的第一天/最后一天
    df[] + pd.Timedelta(days=1)，增加一天，也可以增加周，时，分，秒，参数都是复数形式，加不了年和月
②滚动操作
    df[].rolling(3).mean()，意思就是将每行数据与上面两行数据计算三行数据的平均值，向上寻找
    df[].rolling(3).max()/min()/std()，与上行同理，可以接各种函数计算
    df[].expanding().mean()，每一行数据与以上所有数据进行一个平均值计算，滚动累计的操作
    df.to_csv/to_excel/to_dict，将dataframe数据输出csv文件/excel文件/字典
```

- 学习echarts基础
  - 学习链接：[Handbook - Apache ECharts](https://echarts.apache.org/handbook/zh/get-started/)
  - 学习目标：柱状图、统计图

  ```html
  1 - 先定义一个div容器，用于置放表图，id具有唯一性
  <div id="main" style="width: 1000px;height:600px;"></div>
  ```

  ```javascript
  2 - 在script标签内写入脚本，初始化echarts实例
  // 先通过document.getElementById()找到容器，再echarts.init()初始化
  var myChart = echarts.init(document.getElementById('main'));
  ```

  ```javascript
  3 - 配置option，传入数据并加载
  var option = {……};
  myChart.setOption(option);
  ```

  - 柱状图

  ```javascript
  1 - 配置柱状图的option的一些参数
  // 每个类目下数据名称
  legend: {
      data: ['销量', '进货量']
  },
  // 横坐标的类目
  xAxis: {
      data: ['衬衫', '羊毛衫', '雪纺衫', '裤子', '高跟鞋', '袜子']
  },
  // 纵坐标的类目
  yAxis: {},
  // 要展示的具体数据
  series: [
      {
       	// 与legend对应
          name: '销量',
          // 'bar'是指柱状类型
          type: 'bar',
          // 横坐标的一行数据
          data: [5, 20, 36, 10, 10, 20],
          // 每个类目下柱子之间的距离
          barGap: '0%',
          // 每个类目下柱子到最近两侧的距离与类目长度的百分比
          barCategoryGap: '60%',
          // 是否展示柱子背景色
          showBackground: true,
          // 柱子背景色的调色
          backgroundStyle: {
              color: 'rgba(128, 128, 128, 1)'
          }
      },
  ]
  ```
  
  - 折线图
  
  ```javascript
	2 - 配置折线图的option的一些参数
	// 要展示的数据
  series: [
    {
        name: '销量',
        type: 'line',
        data: [5, 20, 36, 10, 10, 20],
        // 鼠标移动到点上便显示数据
        emphasis:{
            label:{
                show: true,
  }}}]
  ```

---

#### 2022-03-11

- 项目编程风格的思考
  - 向组长发送代码，压缩包的命名后面应当带上发送的日期
  - 命名变量应当坚持自己的下划线风格。不要带有get，post，list等单词，一般是命名方法的
  - url的意思是http这一类的地址，文件类地址的命名最好是path，要词能达意，不要乱命名
  - 常量数据存放文件的命名不要用data.py，data太宽泛，应当取个带有constant的好一些
  - 公共方法也要单独放在一个文件，不能跟常量数据存放文件放一起，比较乱
  - 项目根目录需要有README.md，就像西方不能失去耶路撒冷
- 微信项目优化的思考
  - 按上面编程风格的要求，重新整一版代码
  - 以装饰器的形式去优化每一个操作周期的信息输出，进行首尾分割线，输出更直观
- rolling实战题目

```
1 - 首先在给定的csv文件里面，将每一条数据rolling滚动近三年的数据比较计算
2 - 在每一次滚动里，找到近三年的最高价和最低价，设置为另外两个列
3 - 如果本条数据就是近三年的最高价或最低价，则标记为1，设置为另外两个列
4 - 如果本条数据低于近三年最高价的四分之一的价格，则标记为1，设置为另外一个列
5 - 将df数据输出成文件
```

（1）时间模块的年计算

​			a.需要安装第三方库：pip install python-dateutil

​			b.引用到项目里：from dateutil.relativedelta import relativedelta

​			c.简单粗暴的年计算：datetime类型数据 + relativedelta(years=3)

（2）为rolling窗口设计的天数计算函数

```python
def calculate_date(date, amount):
    """
    功能：
        rolling专用函数，根据时间字符串，找到三年前的时间，并在df数据中统计间隔的数据数量
    参数：
        date - 时间字符串
        amount - 最低的数据滚动量
    返回：
        days - 间隔的天数
    """
    if df[df["trade_date"] == date].index[0] + 1 < amount:
        return amount
    else:
        # 求出当前数据的index
        now_index = df[df["trade_date"] == date].index[0]
        # 求出此数据的三年前时间
        past_date = (df.iat[now_index, 0] - relativedelta(years=3)).strftime("%Y%m%d")
        # 但是不能确定这个日期会在表格中存在，所以预设向后顺延的可能
        while True:
            if df[df["trade_date"] == past_date].empty:
                past_date = (pd.to_datetime(start_date) + relativedelta(days=1)).strftime("%Y%m%d")
                continue
            else:
                break
        # 返回两条数据间隔的数据量，用于rolling
        return now_index - df[df["trade_date"] == past_date].index[0] + 1
```

- rolling实战项目接下来的方向
  - 学习javascript语法将json数据解析下来
  - 将数据传输到echarts上面
  - 把echarts部署到网页上
  - 可使用python -m http.server提供端口，生成网页

---

### Week-3

#### 2022-03-14

- rolling项目遇到的问题记录

  1. 年计算

     ```python
     pip install python-dateutil
     from dateutil.relativedelta import relativedelta
     datetime类型数据 + relativedelta(years=3)
     ```

  2. 如何在已有的列中根据条件去生成新的一列，巧妙运用loc方法

     ```
     公式：df.loc[条件，要生成的新列名] = 期望赋值
     ```

  3.  在dataframde数据中有些数据作为空值，其实不用特意过滤空值，echarts折线图会自动忽略'-'

     ```
     df.fillna(value='-', inplace=True)
     ```

  4. 为什么前端读不出来json文件

     ```
       我原本打算以列表为值后自己生成json直接传给前端，然后发现前端死活读取不了json文件，到后面我才发现to_json这个方法会把NaN值转化为'NaN',而自己生成的列表自己生成的json中，键值是NaN，前端无法读取这个数据类型自然报错，从而无法加载json文件转化为javascript的object对象
     ```

- echarts项目优化进展

  - 如何在鼠标在图表中移动时，能展示出一个横坐标对应多种纵坐标数据的提示框效果？

    ```javascript
    tooltip.trigger = 'axis' 结合 tooltip.formatter
    {a}：系列名称、{b}：横坐标值、{c}纵坐标值
    ```

- 股票知识恶补

  - 股票的价格是什么？

    ```
    股票的价格 = 每股收益 x 市盈率
    ```

  - 股价是如何形成的？

    ```
    股价的形成分为集合竞价和连续竞价。
    1 - 集合竞价：股市在9点半正式开盘前，根据当天早晨买卖双方的委托所形成的价格。
    2 - 连续竞价：股市在9点半正式开盘后，根据买卖双方的委托形成的价格。
    ```

  - L1行情和L2行情是什么？

    ```
    L1行情 - Level1交易所基本行情
    	数据内容：股票、债券、基金和指数等业务品种的行情信息
    	挂单委托：5档
    	成交明细：分笔
    	最优委托：无
    	频度：3秒
    L2行情 - Level2交易所新一代增强行情
    	数据内容：同Level1，但增加了增值信息
    	挂单委托：10档
    	成交明细：逐笔
    	最优委托：前1档50笔
    	频度：3秒
    ```

  - 集合竞价和连续竞价分别是什么意思？

    ```
    剩余笔记请转当前目录下的<股票笔记.md>，记录股票相关知识学习心得
    ```
    

---

#### 2022-03-15

- 配置某证券的SDK，尝试获取Tick行情数据

---

#### 2022-03-16

- 思考Python工程的目录结构，尽可能使项目看上去更规范
  
  - `README.md`记录项目的信息，还可以查阅一些高频使用的数据接口信息
  - `pip install >requirements.tx`t生成文件放根目录，目的是记录所需要安装的第三方库以及对应版本
  - `main.py`的代码尽可能简洁精炼，负责一个程序总入口的作用，运行过程写在别处
  
- 记录了某证券SDK返回的数据详情，每一个item的意思均已搞清楚
  
- MongoDB的使用
  
  - 免费开源的可视化工具下载，推荐RoBo 3T，[Robomongo](https://robomongo.org/download)
  - pymongo的安装使用注意事项
  
  ```
  1 - pymongo的版本尽可能地与MongoDB数据库的版本一致
  2 - pymongo的使用如果报错，那就尽可能降低版本，目前降低到pymongo==3.12
  3 - authSource参数的意思是数据库名称，authMechanism的参数在pymongo3.0版本之后都是"SCRAM-SHA-1"
  ```
  
  - pymongo的学习记录
  
  ```
  一定补上
  ```
  
- 项目后续规划

  - 因为股市的时间是固定的，每天只有四小时多的开放时间，还双休，所以需要加个时间判定函数
  - 在每一条Tick数据经过时间判定函数之后再选择归宿，使程序看上去更高效

---

#### 2022-03-17

- MongoDB数据库用户无权限问题
  - 在MongoDB数据中输入以下两句
  - `use admin`  先进入admin数据库
  - `db.createUser({"user":"user", "pwd":"pwd", "roles":["root"]})`  直接创建超级管理员
  - 这样一来创建数据库和创建集合就畅通无阻了
- 项目进展
  - 通过一天的Tick数据观察，抓取出特征时间段分割股市的各个时间段
  - 已经根据不同的股市时间段给数据打上标签，比如集合竞价时的数据，连续竞价时的数据
  - 已经优化数据的写入规范
  - 将项目写入github桌面版，比对每次提交的代码变化
- 项目优化计划
  - 一个个查看数据，鼠标点的头痛，接入logging日志系统
  - 股市在周六和周日是不上班的，需要补充不工作的条件，考虑是停止SDK的读取还是TICK数据的写入
  - 对于数据固定的时间段，也就是除了集合竞价和连续竞价之外的两个时间段，考虑减少数据的写入

---

#### 2022-03-18

- 项目优化
  - 接入logging系统，实现将不同的数据输入到不同的日志文件
  - 记住，想要实现输出到不同的日志文件，在每轮操作之中都要移除掉handlers对象，不然的话，每次输出只能输出到同一份日志文件
- 配置内部gitlab，规定后续的开发流程
  - 先在本地git bash配置好连接使用，将项目git clone到本地
  - `git checkout -b xxx`，基于master分支创建一个开发分支xxx
  - 完成开发之后，进行git add  + commit提交改动
  - `git push origin xxx`，将本地的分支推送到远程上面
  - 回到内部gitlab网页端，发起一个合并请求，并自查代码的变动
  - 组长审批合并请求，二次审查代码的改动，并点击同意合并
  - 开发者回到本地git bash，`git checkout master`回到master分支
  - `git branch -d xxx`，删除已经合并的开发分支
  - `git pull`，更新master分支完成整个开发周期
  - 后续优化：如果项目组规模扩大，则增加测试服和测试分支dev，合并到dev分支并去测试服完成测试才能发起对matser的合并请求

---

### Week 4

#### 2022-03-21

- 华泰项目进一步拓展与思考
  - 当我们把股票代码列表加到40只的时候，我们发现，数据依旧没问题，但是我们的日志系统错乱了
  - 本来我设计的初衷是不同的股票数据写入不同的日志文件，但是我们发现部分日志已经出现了污染现象
  - 部分日志存在数据写入交错的问题，说明并发控制地并不好，各线程未独立，所以这不得不想办法进行一次优化，解决在数据过多的情况下交错写入日志的问题。
- 交错写入日志发生数据污染的问题
  - 首先分析logging系统本身为什么会产生数据污染，在之前的源码中，我使用了`logger.addHandler()`和`logger.removeHandler()`配套操作，希望在每一轮操作结束时及时删除日志文件处理对象，来保证每个日志文件的独立。因为如果不移除日志文件处理对象，所有的数据只能写入同一份日志文件。那么为什么还是发生了数据污染，我采用了`print()`调试打印观察信息，发现到了后面，还是有些日志文件处理对象没有被及时移除出去，就进入了下一轮操作，我的第一反应是，难道Python速度跟不上了？
  - 事实已经摆在面前，不必纠结为什么不完成一个函数流程就进入下一轮操作，我开始思考优化的方法，既然`logger.removeHandler()`跟不上，那我直接从头到尾直接赋值`logger.handlers = [fh]`指定只有符合要求的日志文件处理对象，然后结尾再补个`logger.handlers = []`进行暴力清空，这总没问题了吧？
  - 然后日志函数运行的位置，也引发了我的思考，我为什么不能深入源码揪出真正的位置？于是我还是进入了tushare包的源码，找到了一处`thread_pool.submit(func, ts_record, inst_data)`位置，这儿已经被赋值成了线程池，来保证每次Tick数据发送的顺利性，这儿我需要记录一下选择，因为股市在下午三点就停止了，所以明天再验证更好的选择：
    - 日志函数放在thread_pool语句下面
    - 日志函数放在被装饰的func里面，跟写入MongoDB的代码并排放一起
  - 然后就是双休的时间判断，打算封装成装饰器形式。我的初衷是能节省程序性能就节省，所以打算把判断双休的条件放在最前面，但也不至于断掉一直获取SDK数据的行为导致程序中止，当然了，也废了不少的力气去定位，突然间我想到主函数也是被装饰器修饰的，我为什么不去找到装饰器内部的函数去修饰，这样一来也定位到了正确的装饰器位置。但是，这个时候我又挖了一个新坑：
    - 双休的判定是有了，但是法定节假日呢？国家规定的调休日呢？
    - 这些日子肯定也是不工作的，那在代码里应该怎么判断呢？

---

#### 2022-03-22

- 日志输出函数位置的验证
  - 放在thread_pool语句下面，一切正常，数据未被污染
  - 放在thread_pool里的func函数里面，一切正常，数据未被污染，敲定此方案，放在线程池一起操作更好
  
- 股市交易日的判断
  - tushare pro上获取今天是否为交易日需要一定的积分权限，故申请拿了组长的token进行操作
  - 刚开始使用的时候发现token是有访问频率的，一分钟最多为500次
  - 我想了一个key本地化方案，一天只需要访问一次tushare接口，将当天的日期和结果存放在本地文件，后面的访问只需要核对今天的日期就能得到是否为交易日的结果，如果是第二天访问，则更新本地文件的数据，实现了此需求的资源利用最小化，不需要利用数据库。
  - 组长说交易日历已经打入数据库，直接获取访问，此方案暂不采纳，减轻数据库的读取压力。
- 项目是否能在Windows虚拟机上走通
  - 初步测试，暂无发现问题，能够流畅运行
- 能否使用更好的自动微信程序模块
  - 待定研究
- 数据存储工作和代码整理工作已经完毕，现在进入分析数据阶段
  - 程序是在thread_pool运行的，每一条Tick数据将会各个线程池中完成写入MongDB和输出到日志文件
  - 所以，每一条Tick数据的元操作是写入数据库和输出日志，组成了我们现在的项目
  - 那么，分析数据该如何下手？
  - 如果在元操作内加入数据分析，怎么承之前的数据，怎么接后来的数据？
    - 如果在元操作内加入数据分析，可以考虑开一个新数据库，将每次的Tick数据的关键信息写入进去
    - 然后每次以固定切片的长度访问之前的数据，结合Python的collections模块进行规则运算
    - 会不会线程的执行效率不够？
  - 如果在元操作外加入数据分析，面对持续生成新数据的项目，怎么找到分析的切入口？
    - sdk程序属于死循环，要实现sdk程序之外再开一个进程去专门的数据分析
    - 利用multiprocessing模块开两个单位的进程池，一个数据存储，一个数据分析，交叉工作
    - 关键是如何找到分析的切入口，监听日志文件内容的变化，还是监听数据库的内容变化
    - 能不能在新开的进程里面，再开线程池，监听40个数据来源的变动，进一步做分析
    - 这样就是第一个进程的线程池负责获取和存储数据，第二个进程的线程池负责监听和分析数据

---

#### 2022-03-23

- 主要是完成华泰项目与微信项目的代码拼接

  - 微信项目与华泰项目分别设置为两个进程

  ```python
  import multiprocessing
  # 两个进程的代码示范
  function_list = [fun1, fun2]
      pool = multiprocessing.Pool(2)
      for func in function_list:
          pool.apply_async(func)
      pool.close()
      pool.join()
  ```

  - 微信项目目前的发送消息逻辑，开始爬数据之前定位到微信句柄，选择好群组，然后才执行源源不断的复制粘贴，此过程要求全程不动鼠标。
    - 全程不能动鼠标，且微信窗口是放大的，看不到终端的数据输出，不灵活
    - 速度慢，因为是模拟鼠标模拟键盘操作，必定是跟不上数据，后期可能需要换成调用api
    - 目前如果没有能力换成调用api的话，缓兵之计是几十条消息合并成一张图片并发送，缺点是数据的延迟性更加明显了，不算是一个很好的策略方案，因为现在的交易竞争已经是自动化，看到了微信消息再去手机上手动操作必定是来不及
  - 微信项目的小策略选择之买卖5档
    - 差额 = 卖1与买1之间的空档正差额，占比 = 差额/当前价格 x 100%
    - 问题1：非连续竞价期间的数据没有参考意义
    - 问题2：连续竞价期间遭到跌停的股票也符合模型，因为没有买的数据
    - 问题3：抓取不到成长性明显很强的股票，因为这种股票不存在买卖空档，这个小策略局限性很大
    - 问题4：缺少一个前置模型的数据分析，无法判断这只股票过去的走线情况，只看空档效率很低

---

#### 2022-03-24
